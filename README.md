# Attention-feelings
Developed in the Quantitative Methods and Models course by: Kevin Reyes.
## Objectives
- Evaluate the effectiveness of increasing or decreasing the level of attention after training.

## Description
Analysis of variation in weighting of weights in attention mechanisms of recurrent neural networks in the prediction of feelings.

## Conclusions
- By inverting the post-training attention mechanism, the performance of the network worsens considerably.
- By slightly maximizing the post-training attention mechanism, small improvements can be obtained in the generalization capacity of the neural network.
- By significantly maximizing the attention mechanism, the performance of the network worsens.

## Technology stack
- Numpy.
- Nltk.
- Tensorflow.
- Keras.
- Matplotlib.
- Seaborn.
- Scikit-learn.
- Pandas.